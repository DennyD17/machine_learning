{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простая классификация по тональности\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем данные с сайта Кинопоиск: последние 200 положительный, 200 нейтральных и 200 отрицательных отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/1/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/2/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/3/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/4/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/5/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/6/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/7/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/8/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/9/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/10/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/11/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/12/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/13/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/14/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/15/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/16/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/17/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/18/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/19/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/bad/period/month/page/20/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/1/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/2/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/3/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/4/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/5/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/6/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/7/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/8/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/9/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/10/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/11/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/12/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/13/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/14/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/15/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/16/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/17/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/18/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/19/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/page/20/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/1/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/2/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/3/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/4/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/5/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/6/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/7/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/8/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/9/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/10/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/11/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/12/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/13/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/14/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/15/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/16/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/17/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/18/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/19/#list\n",
      "http://www.kinopoisk.ru/reviews/type/comment/status/neutral/period/month/page/20/#list\n",
      "200 200 200\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as urllib2\n",
    "import http.cookiejar as cookielib\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "\n",
    "cookie = cookielib.CookieJar()\n",
    "req = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))\n",
    "req.addheaders = [('User-Agent',\n",
    "                   'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2) AppleWebKit/600.3.18 (KHTML, like Gecko) Version/8.0.3 Safari/600.3.18')]\n",
    "\n",
    "\n",
    "def get_review_urls(main_url):\n",
    "    reviews = []\n",
    "    for i in range(1, 21):\n",
    "        cur_url = main_url + 'period/month/page/'+str(i)+'/#list'\n",
    "        print(cur_url)\n",
    "        resp = req.open(cur_url).read()\n",
    "        soup = BeautifulSoup(resp, 'html.parser', from_encoding='UTF-8')\n",
    "        for review in soup.find_all('span', {'class': '_reachbanner_', 'itemprop': \"reviewBody\"}):\n",
    "            reviews.append(review.text)\n",
    "    return reviews\n",
    "\n",
    "\n",
    "bad_main_url = 'http://www.kinopoisk.ru/reviews/type/comment/status/bad/'\n",
    "bad_urls = get_review_urls(bad_main_url)\n",
    "\n",
    "good_main_url = 'http://www.kinopoisk.ru/reviews/type/comment/status/good/'\n",
    "good_urls = get_review_urls(good_main_url)\n",
    "\n",
    "neutral_main_url = 'http://www.kinopoisk.ru/reviews/type/comment/status/neutral/'\n",
    "neutral_urls = get_review_urls(neutral_main_url)\n",
    "\n",
    "print(len(bad_urls), len(good_urls), len(neutral_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсер html страничек с отзывами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in c:\\users\\admin\\workspace\\machine_learning\\datascienceenv\\lib\\site-packages\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\workspace\\machine_learning\\datascienceenv\\lib\\site-packages (from pymystem3)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\admin\\workspace\\machine_learning\\datascienceenv\\lib\\site-packages (from requests->pymystem3)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\admin\\workspace\\machine_learning\\datascienceenv\\lib\\site-packages (from requests->pymystem3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\workspace\\machine_learning\\datascienceenv\\lib\\site-packages (from requests->pymystem3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\admin\\workspace\\machine_learning\\datascienceenv\\lib\\site-packages (from requests->pymystem3)\n"
     ]
    }
   ],
   "source": [
    "! pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['reviews'] = []\n",
    "for i in bad_urls: \n",
    "    data['reviews'].append({'review':i, 'class':'negative'})\n",
    "for i in good_urls: \n",
    "    data['reviews'].append({'review':i, 'class':'positive'})\n",
    "for i in neutral_urls: \n",
    "    data['reviews'].append({'review':i, 'class':'neutral'})\n",
    "\n",
    "import json\n",
    "with open('kino_data.txt', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартная предобработка данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск предобработки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of reviews: 600\n",
      "Фильм ужасен и притягателен, как может быть притягательным физическое уродство. Во всяком случае, 2 часа пролетают практически незаметно, хотя, не скрою, пару раз возникало желание выключить все и забыть увиденное, как страшный сон. Несомненно, сильная игра актеров, несомненно, превосходная драматургия, несомненно, трагедия человеческой жизни. И вот тут возникает странный дуализм. Надо бы пожалеть героиню Изабель Юппер Эрику, надо бы, но",
      " \n",
      "\r\n",
      "Уже с первых минут возникает неприязнь, которая нарастает с каждым эпизодом фильма. Что мы имеем? А имеем мы женщину, которая ради карьеры пианистки превратила свою жизнь в рабство. Могла она уйти от матери-тирана, задавившую ее своей опекой? Нет, не любовью, а опекой человека, который сам не смог добиться чего-то стоящего в жизни. Могла, но не ушла. Мать  этот жуткий паук с повадками интеллигентки  приковала дочь такими цепями, которые трудно разорвать: они как пуповина, которая соединяет мать и детеныша в ее чреве. Однако беда в том, что Эрика не захотела ничего менять, даже постель, которую на протяжении всей своей жизни делила с матерью. Но если женщина в 40 лет продолжает спать в одной постели с матерью, имея свою комнату  это клиника, шизофрения. Эрика  униженный и душевно распятый человек, такие не становятся героями, зато превращаются в маньяков. Именно это мы и увидели. Эрика не стала известной на весь мир пианисткой. Да, она  профессор, ученики выстраиваются к ней в очередь, но ее удел  домашние концерты. \n",
      "\r\n",
      "Она  неудачница, обернутая в красивый фантик своей должности. И на эту канву накладывается психическое расстройство на почве эротической неудовлетворенности, которое множится с неимоверной скоростью после появления Вальтера. Если бы автор фильма на этом остановился, на мой взгляд, был бы шедевр, но для чего-то перед нами вываливают такую грязь и не просто вываливают, а смакуют ее в каждом кадре, что возникает нестерпимое отвращение к происходящему на экране. Я не смогу ответить на вопрос стоит ли смотреть этот фильм  пусть каждый решает сам. Но однозначно пересматривать не буду.\n",
      "\n",
      "\r\n",
      "3 из 10\n",
      "\r\n",
      " только за игру Изабель Юппер. negative\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('kino_data.txt') as infile:\n",
    "    data = json.load(infile)\n",
    "print('N of reviews:', len(data['reviews']))\n",
    "texts = []\n",
    "target = []\n",
    "for r in data['reviews']:\n",
    "    text = r['review'].strip()\n",
    "    texts.append(text)\n",
    "    target.append(r['class'])\n",
    "print (texts[10], target[10])\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "150 случайных документов – обучающая выборка, остальные 50 - тестовая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109, 20, 50, 0, 118, 191, 108, 117, 186, 46, 38, 155, 124, 200, 63, 18, 55, 24, 85, 112, 166, 192, 92, 48, 21, 162, 160, 181, 69, 168, 60, 98, 54, 178, 45, 47, 116, 91, 187, 16, 52, 161, 193, 189, 79, 97, 9, 134, 44, 163, 125, 17, 153, 82, 103, 14, 74, 188, 95, 53, 133, 195, 68, 136, 88, 36, 84, 5, 148, 127, 80, 7, 122, 31, 164, 57, 101, 154, 115, 33, 169, 171, 11, 149, 106, 27, 42, 132, 26, 173, 19, 119, 121, 185, 22, 67, 120, 157, 107, 30, 73, 83, 142, 126, 86, 75, 152, 197, 66, 180, 90, 87, 41, 175, 65, 198, 8, 131, 183, 177, 81, 102, 141, 71, 94, 2, 138, 196, 140, 184, 170, 174, 78, 76, 158, 29, 58, 110, 111, 156, 194, 23, 159, 3, 28, 35, 34, 1, 146, 100, 264, 289, 316, 226, 300, 378, 383, 247, 343, 219, 269, 201, 308, 353, 313, 323, 371, 361, 275, 360, 279, 345, 326, 298, 379, 336, 288, 203, 299, 238, 387, 225, 237, 373, 283, 295, 388, 340, 259, 301, 376, 335, 235, 364, 311, 210, 325, 266, 293, 391, 280, 243, 312, 233, 296, 211, 392, 287, 257, 270, 209, 306, 309, 250, 267, 262, 212, 242, 337, 356, 347, 332, 370, 236, 339, 302, 261, 355, 254, 341, 398, 215, 350, 307, 389, 344, 351, 222, 328, 303, 365, 321, 372, 366, 265, 342, 207, 205, 202, 272, 349, 382, 285, 322, 327, 286, 304, 330, 231, 399, 217, 346, 227, 385, 318, 368, 256, 220, 297, 216, 273, 228, 292, 354, 375, 271, 331, 386, 352, 338, 208, 277, 251, 314, 253, 400, 359, 232, 319, 290, 221, 230, 348, 384, 213, 390, 234, 246, 260, 245, 413, 587, 559, 539, 460, 417, 455, 426, 516, 567, 416, 579, 408, 450, 441, 553, 504, 473, 563, 432, 503, 464, 484, 568, 565, 511, 517, 457, 443, 488, 527, 597, 485, 496, 402, 541, 575, 438, 479, 576, 582, 532, 444, 566, 536, 528, 497, 548, 547, 531, 506, 477, 425, 591, 495, 554, 436, 538, 564, 583, 508, 526, 519, 551, 490, 429, 543, 401, 420, 456, 505, 589, 572, 522, 487, 453, 465, 590, 498, 472, 470, 469, 424, 466, 509, 412, 405, 584, 586, 570, 557, 571, 463, 561, 431, 423, 507, 550, 403, 482, 475, 411, 414, 521, 461, 430, 512, 524, 549, 544, 434, 481, 462, 533, 447, 515, 449, 588, 458, 404, 502, 578, 478, 500, 451, 535, 459, 410, 585, 445, 596, 594, 422, 518, 537, 419, 409, 540, 514, 428, 525, 480, 595, 433, 523, 555, 574, 491, 421, 593]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_idx = random.sample(range(0,201),  150) + random.sample(range(200, 401),  150) + random.sample(range(400, 600),  150) \n",
    "print (train_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формирование обучающей выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "150\n",
      "149\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "train_texts = []\n",
    "train_target = []\n",
    "test_texts = []\n",
    "test_target = []\n",
    "\n",
    "for t_id in range(len(texts)):\n",
    "    if t_id in train_idx:\n",
    "        train_texts.append(texts[t_id])\n",
    "        train_target.append(target[t_id])\n",
    "    else:\n",
    "        test_texts.append(texts[t_id])\n",
    "        test_target.append(target[t_id])        \n",
    "        \n",
    "\n",
    "print (train_target.count('neutral')) \n",
    "print (train_target.count('positive')) \n",
    "print (train_target.count('negative')) \n",
    "print (len(train_target)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация на три класса и матрица ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "import time\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "    level=logging.INFO)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#from gensim.models import Word2Vec # библиотека gensim, в которой реализовано много Deep Learning алгоритмов\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"russian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    letters_only = re.sub(\"[^а-яА-Я]\", \" \", raw_review) \n",
    "    words = letters_only.lower().split()                             \n",
    "    stops = set(stopwords.words(\"russian\"))                  \n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_clean = []\n",
    "for text in train_texts:\n",
    "    train_text_clean.append(review_to_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "цитата вверху написанная гоголем сво м произведении м ртвые души выпущенном году наверное отображает создание данного фильма вообще искусства целом такового мало хотеть нужно постараться стало выдающимся шедевром стало модно это называть великие картины художников давинчи пикассо создавались несколько дней прекрасные романы писателей написаны балды великолепные картины режисс ров любим пересматриваем раза создавались тяж лым трудом именно поэтому называем это искусством сделанное талантом любовью это становится настоящим шедевром оставляя сердцах многих людей любовь века стоит говорить создатели гоголя начало оставят память истории извиняюсь искренне насмешил понятное дело сомневаюсь дня просмотра вс просмотренное вылетит головы это совершенно пустое кино ладно такое выходило игнорировалось рекламная компания обязательно сделает сво дело пойд т чисто неведению проверить сказать любопытству души это самом случае раздражает люди сами порождают плохие фильмы разом поощряя рубл м удивлюсь фильма продолжение ещ ещ ещ задумайтесь достоин просто ваших денег вообще внимания времени кино котором гоголь лишь предлог мистики сюжет скопирован тысячи других фильмов кровь принципу д рганый монтаж никак называется хорошим спасибо режисс ру некоторые отсылки произведениям гоголя какую хотя схожесть вроде фобий критично мало больший упор делается мистику саспенс загадочность молодцы подобного рода подходе сочтите дерзость российские ремесленники совершенно беззубы кинематографу россии ещ идти идти выглядит вс д шево смешно это ужастик самого лучшего производства х годов сняли чисто фану безусловно доля мрачности чувствуется основном сч т припадком гоголя сон смешивается реальностью образуя сюрреализм первых это клише своего вторых сделано это капли индивидуальности такое ощущение возникло просто скопировали сцены других таких фильмов третьих графика позволяет ощутить самом деле другими словами погружаешься атмосферу это значит лишь одно идею атмосферу создатели профукали итоге подарить гоголь начало смех злость одну сексуальную сцену мало вписывающуюся сюжет море бутафорской крови точно приятные впечатления эмоции\n"
     ]
    }
   ],
   "source": [
    "print(train_text_clean[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "train_clean_lem = []\n",
    "m = Mystem()\n",
    "for text in train_text_clean:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "заводить наш бренный мир выход второй часть полюбиться фильм часто знаменовать себя жестокий разочарование кинолента золотой кольцо сожаление становиться исключение начн м краткий синопсис штаб квартира разрушать весь мир заложник неизвестный робкий луч надежда благополучный разрешение непростой ситуация забрезжить британский спецагент узнавать аналогичный секретный организация штаб квартира который располагаться сша именно фильм представлять трейлер прич м мой наблюдение трейлер оставлять среднестатистический зритель безотчетный неизбывный послевкусие вторичность безыдейность считать свой долг предостерегать предчувствие обманывать сюжет золотой кольцо настолько избивать настолько испещр н сюжетный дыра настолько изобиловать неоправданный сценарный допущение середина фильм становиться абсолютно безразлично разрешаться основной конфликт неприличие растянутый хронометраж заставлять нетерпение ждать заветный момент это действо заканчиваться несмотря зв здный актерский состав никто герой раскрывать достаточно всесторонне глубоко зритель возникать хотя л гкой смутный желание кто настоящий сопереживать кроме возможно элтон джон технический точка зрение фильм весьма неплохой некоторый боевой сцена снимать довольно качественно креативный равный такой сцена слишком редкий отрывочный искупать тот феерический посредственность неловкий фарсовость который фильм истязать зритель возможно элтон джон протяжение хронометраж итог мы бледный выхолащивать продукт киноиндустрия нацеливать коммерческий успех фильм ради фильм это говорить ряд довольно скольким затрагивать фильм несколько нетрадиционный ракурс среди оправдание употребление наркотик алкоголь беспорядочный половой связь участие женщина легкий поведение возможно элтон джон\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (train_clean_lem[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 5000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = stopwords.words('russian'),   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(train_clean_lem)\n",
    "\n",
    "# важно помнить, что sklearn на вход принимает numpy arrays, поэтому сконвертируем сразу\n",
    "train_data_features = train_data_features.toarray()\n",
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['абсолютно', 'абсолютный', 'абсурд', 'абсурдность', 'абсурдный', 'август', 'авиакатастрофа', 'автобус', 'автомобиль', 'автор', 'авторский', 'агент', 'агитка', 'агрессивный', 'ад', 'адам', 'адамс', 'адаптация', 'адаптировать', 'адекватно', 'адекватный', 'адрес', 'адский', 'аж', 'айзек', 'ака', 'акт', 'актер', 'актерский', 'активно', 'активный', 'актриса', 'актуальный', 'акцент', 'алан', 'алекс', 'александр', 'алексей', 'алена', 'алкоголик', 'алкоголь', 'алкогольный', 'аллюзия', 'алый', 'альманах', 'альтернативный', 'амбициозный', 'амбиция', 'америка', 'американец', 'американский', 'амин', 'амплуа', 'ана', 'анализ', 'анализировать', 'аналог', 'аналогичный', 'аналогия', 'ангел', 'английский', 'англичанин', 'англия', 'андерсон', 'анджелес', 'андрей', 'андроид', 'анекдот', 'аниме', 'анна', 'аннабель', 'ансамбль', 'антагонист', 'антигерой', 'антиутопия', 'антихрист', 'антология', 'антониони', 'антураж', 'аплодировать', 'апогей', 'апокалипсис', 'априори', 'ардан', 'арестовывать', 'аритмия', 'армас', 'армия', 'аронофски', 'арт', 'артист', 'артур', 'артхаус', 'артхаусный', 'архангел', 'аспект', 'ассоциация', 'ассоциироваться', 'атмосфера']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1462 это\n",
      "1308 который\n",
      "706 свой\n",
      "621 человек\n",
      "559 герой\n",
      "552 первый\n",
      "495 вс\n",
      "491 очень\n",
      "478 самый\n",
      "457 персонаж\n",
      "448 год\n",
      "428 время\n",
      "422 просто\n",
      "396 сюжет\n",
      "393 главный\n",
      "377 картина\n",
      "361 часть\n",
      "360 хороший\n",
      "360 история\n",
      "358 зритель\n",
      "324 становиться\n",
      "318 кино\n",
      "305 весь\n",
      "302 сцена\n",
      "302 показывать\n",
      "298 смотреть\n",
      "284 сказать\n",
      "279 мочь\n",
      "278 снимать\n"
     ]
    }
   ],
   "source": [
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "for count, tag in sorted([(count, tag) for tag, count in zip(vocab, dist)], reverse=True)[1:30]:\n",
    "    print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the random forest...\")\n",
    "forest = RandomForestClassifier(n_estimators = 150, n_jobs=-1) \n",
    "forest = forest.fit( train_data_features, train_target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_reviews = [] \n",
    "for text in test_texts:\n",
    "    clean_test_reviews.append(review_to_words(text))\n",
    "\n",
    "test_clean_lem = []\n",
    "m = Mystem()\n",
    "for text in clean_test_reviews:\n",
    "    test_clean_lem.append(''.join(m.lemmatize(text)))\n",
    "# т.к. словарь уже есть(ВАЖНО - СЛОВАРЬ ЗАНОВО СТРОИТЬ НЕНАДО, нужно делать НЕ fit_transform, а ПРОСТО transform!!!)\n",
    "test_data_features = vectorizer.transform(test_clean_lem)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# передаем фичи натренированной модели\n",
    "result = forest.predict(test_data_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.61      0.75      0.67        51\n",
      "    neutral       0.54      0.53      0.54        49\n",
      "   positive       0.75      0.60      0.67        50\n",
      "\n",
      "avg / total       0.64      0.63      0.63       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(test_target, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38 10  3]\n",
      " [16 26  7]\n",
      " [ 8 12 30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_target, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626666666667\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(test_target, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация на два класса и матрица ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['reviews'] = []\n",
    "for i in bad_urls: \n",
    "    data['reviews'].append({'review':i, 'class':'negative'})\n",
    "for i in good_urls: \n",
    "    data['reviews'].append({'review':i, 'class':'positive'})\n",
    "\n",
    "import json\n",
    "with open('kino_data_bool.txt', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of reviews: 400\n",
      "Фильм ужасен и притягателен, как может быть притягательным физическое уродство. Во всяком случае, 2 часа пролетают практически незаметно, хотя, не скрою, пару раз возникало желание выключить все и забыть увиденное, как страшный сон. Несомненно, сильная игра актеров, несомненно, превосходная драматургия, несомненно, трагедия человеческой жизни. И вот тут возникает странный дуализм. Надо бы пожалеть героиню Изабель Юппер Эрику, надо бы, но",
      " \n",
      "\r\n",
      "Уже с первых минут возникает неприязнь, которая нарастает с каждым эпизодом фильма. Что мы имеем? А имеем мы женщину, которая ради карьеры пианистки превратила свою жизнь в рабство. Могла она уйти от матери-тирана, задавившую ее своей опекой? Нет, не любовью, а опекой человека, который сам не смог добиться чего-то стоящего в жизни. Могла, но не ушла. Мать  этот жуткий паук с повадками интеллигентки  приковала дочь такими цепями, которые трудно разорвать: они как пуповина, которая соединяет мать и детеныша в ее чреве. Однако беда в том, что Эрика не захотела ничего менять, даже постель, которую на протяжении всей своей жизни делила с матерью. Но если женщина в 40 лет продолжает спать в одной постели с матерью, имея свою комнату  это клиника, шизофрения. Эрика  униженный и душевно распятый человек, такие не становятся героями, зато превращаются в маньяков. Именно это мы и увидели. Эрика не стала известной на весь мир пианисткой. Да, она  профессор, ученики выстраиваются к ней в очередь, но ее удел  домашние концерты. \n",
      "\r\n",
      "Она  неудачница, обернутая в красивый фантик своей должности. И на эту канву накладывается психическое расстройство на почве эротической неудовлетворенности, которое множится с неимоверной скоростью после появления Вальтера. Если бы автор фильма на этом остановился, на мой взгляд, был бы шедевр, но для чего-то перед нами вываливают такую грязь и не просто вываливают, а смакуют ее в каждом кадре, что возникает нестерпимое отвращение к происходящему на экране. Я не смогу ответить на вопрос стоит ли смотреть этот фильм  пусть каждый решает сам. Но однозначно пересматривать не буду.\n",
      "\n",
      "\r\n",
      "3 из 10\n",
      "\r\n",
      " только за игру Изабель Юппер. negative\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('kino_data_bool.txt') as infile:\n",
    "    data = json.load(infile)\n",
    "print('N of reviews:', len(data['reviews']))\n",
    "texts = []\n",
    "target = []\n",
    "for r in data['reviews']:\n",
    "    text = r['review'].strip()\n",
    "    texts.append(text)\n",
    "    target.append(r['class'])\n",
    "print (texts[10], target[10])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 171, 28, 199, 115, 172, 61, 17, 10, 168, 8, 37, 42, 65, 139, 157, 162, 15, 54, 193, 188, 35, 134, 200, 195, 182, 164, 9, 23, 107, 66, 95, 153, 178, 75, 60, 119, 146, 110, 50, 80, 51, 85, 179, 148, 89, 44, 165, 7, 88, 45, 163, 40, 72, 121, 111, 155, 131, 174, 2, 20, 67, 79, 189, 145, 141, 92, 46, 87, 117, 152, 31, 126, 59, 29, 36, 106, 120, 27, 100, 196, 151, 173, 118, 192, 30, 194, 166, 190, 82, 5, 76, 127, 52, 39, 96, 156, 124, 86, 147, 154, 56, 93, 57, 13, 55, 26, 183, 1, 77, 150, 64, 68, 22, 47, 53, 98, 90, 3, 62, 14, 109, 123, 130, 175, 161, 176, 78, 128, 71, 108, 81, 114, 99, 160, 16, 18, 180, 33, 187, 113, 41, 38, 21, 122, 137, 170, 12, 159, 129, 212, 314, 386, 324, 282, 291, 296, 352, 242, 347, 339, 338, 208, 329, 362, 376, 310, 328, 244, 236, 271, 389, 302, 323, 239, 357, 297, 233, 207, 400, 370, 281, 225, 221, 247, 234, 218, 254, 224, 202, 304, 250, 269, 383, 377, 220, 264, 332, 240, 365, 320, 311, 305, 216, 381, 371, 300, 340, 243, 341, 289, 336, 275, 279, 342, 394, 331, 276, 237, 258, 368, 312, 315, 200, 316, 292, 210, 262, 319, 227, 335, 295, 344, 213, 349, 228, 273, 280, 266, 259, 272, 369, 399, 230, 354, 211, 268, 327, 306, 265, 222, 253, 294, 322, 398, 293, 326, 387, 359, 283, 214, 232, 290, 286, 256, 348, 261, 364, 382, 219, 363, 345, 229, 209, 303, 372, 287, 392, 333, 318, 358, 203, 252, 373, 257, 351, 248, 325, 390, 246, 278, 201, 355, 397, 274, 267, 260, 307, 395, 255]\n"
     ]
    }
   ],
   "source": [
    "train_idx = random.sample(range(0,201),  150) + random.sample(range(200, 401),  150)\n",
    "print (train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "149\n",
      "149\n",
      "298\n"
     ]
    }
   ],
   "source": [
    "train_texts = []\n",
    "train_target = []\n",
    "test_texts = []\n",
    "test_target = []\n",
    "\n",
    "for t_id in range(len(texts)):\n",
    "    if t_id in train_idx:\n",
    "        train_texts.append(texts[t_id])\n",
    "        train_target.append(target[t_id])\n",
    "    else:\n",
    "        test_texts.append(texts[t_id])\n",
    "        test_target.append(target[t_id])        \n",
    "        \n",
    "\n",
    "print (train_target.count('neutral')) \n",
    "print (train_target.count('positive')) \n",
    "print (train_target.count('negative')) \n",
    "print (len(train_target)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_clean = []\n",
    "for text in train_texts:\n",
    "    train_text_clean.append(review_to_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_lem = []\n",
    "m = Mystem()\n",
    "for text in train_text_clean:\n",
    "    train_clean_lem.append(''.join(m.lemmatize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298, 5000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = stopwords.words('russian'),   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(train_clean_lem)\n",
    "\n",
    "train_data_features = train_data_features.toarray()\n",
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['абсолютный', 'абстрактный', 'абсурд', 'абсурдность', 'абсурдный', 'авангардный', 'август', 'авиакатастрофа', 'автомобиль', 'автор', 'авторский', 'ага', 'агент', 'агентство', 'агитка', 'агрессивный', 'ад', 'адамс', 'адаптация', 'адаптировать', 'адекватный', 'адрес', 'адский', 'аж', 'айзек', 'аккуратно', 'акт', 'актер', 'актерский', 'активный', 'актриса', 'актуальный', 'акцент', 'акцентировать', 'алекс', 'александр', 'алексей', 'алена', 'алкоголик', 'алкоголь', 'алкогольный', 'аллюзия', 'алый', 'альтернативный', 'амбициозный', 'амбиция', 'америка', 'американец', 'американский', 'амин', 'амитивилль', 'ана', 'анализ', 'анализировать', 'аналог', 'аналогия', 'ангел', 'ангельский', 'английский', 'англичанин', 'андерсон', 'анджелес', 'андрей', 'андрес', 'андроид', 'анекдот', 'аниме', 'анна', 'аннабель', 'ансамбль', 'антагонист', 'антигерой', 'антиутопия', 'антихрист', 'антураж', 'апатия', 'апогей', 'апокалипсис', 'апофеоз', 'априори', 'аритмия', 'армас', 'армия', 'аронофски', 'арт', 'артист', 'артур', 'артхаус', 'артхаусный', 'архангел', 'архитектор', 'аспект', 'ассоциироваться', 'атмосфера', 'атмосферный', 'аттракцион', 'аудио', 'аудитория', 'афиша']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "988 это\n",
      "861 который\n",
      "492 свой\n",
      "409 человек\n",
      "344 герой\n",
      "342 первый\n",
      "327 самый\n",
      "316 год\n",
      "314 вс\n",
      "304 персонаж\n",
      "304 очень\n",
      "297 время\n",
      "275 просто\n",
      "264 картина\n",
      "261 сюжет\n",
      "254 хороший\n",
      "249 бежать\n",
      "245 зритель\n",
      "243 становиться\n",
      "240 главный\n",
      "238 история\n",
      "227 часть\n",
      "220 кино\n",
      "206 снимать\n",
      "205 мир\n",
      "199 лезвие\n",
      "198 смотреть\n",
      "191 сцена\n",
      "187 весь\n"
     ]
    }
   ],
   "source": [
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "for count, tag in sorted([(count, tag) for tag, count in zip(vocab, dist)], reverse=True)[1:30]:\n",
    "    print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 100, n_jobs=-1) \n",
    "forest = forest.fit( train_data_features, train_target )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_reviews = [] \n",
    "for text in test_texts:\n",
    "    clean_test_reviews.append(review_to_words(text))\n",
    "\n",
    "test_clean_lem = []\n",
    "m = Mystem()\n",
    "for text in clean_test_reviews:\n",
    "    test_clean_lem.append(''.join(m.lemmatize(text)))\n",
    "test_data_features = vectorizer.transform(test_clean_lem)\n",
    "test_data_features = test_data_features.toarray()\n",
    "result = forest.predict(test_data_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.73      0.80      0.77        51\n",
      "   positive       0.78      0.71      0.74        51\n",
      "\n",
      "avg / total       0.76      0.75      0.75       102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(test_target, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754901960784\n"
     ]
    }
   ],
   "source": [
    "print (accuracy_score(test_target, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41 10]\n",
      " [15 36]]\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(test_target, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35-anaconda",
   "language": "python",
   "name": "py35-anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
